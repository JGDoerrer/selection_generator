\documentclass[10pt,journal,compsoc]{IEEEtran}

\usepackage[all,pdf]{xy}
\usepackage{tikz}




% *** CITATION PACKAGES ***
%
\ifCLASSOPTIONcompsoc
  % IEEE Computer Society needs nocompress option
  % requires cite.sty v4.0 or later (November 2003)
  \usepackage[nocompress]{cite}
\else
  % normal IEEE
  \usepackage{cite}
\fi

% *** MATH PACKAGES ***
%
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{todonotes}
\usepackage{nicefrac}
\usepackage{lmodern,amssymb}
\usepackage{float}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usetikzlibrary{positioning}
\usetikzlibrary{shapes.misc}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{pgfplots}
\usepackage{hyperref}
% Commands
\newcommand\smallO{
  \mathchoice
    {{\scriptstyle\mathcal{O}}}% \displaystyle
    {{\scriptstyle\mathcal{O}}}% \textstyle
    {{\scriptscriptstyle\mathcal{O}}}% \scriptstyle
    {\scalebox{.50}{$\scriptscriptstyle\mathcal{O}$}}%\scriptscriptstyle
  }

\interdisplaylinepenalty=2500


\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}

\hyphenation{op-tical net-works semi-conduc-tor}

\makeatletter
\def\endthebibliography{%
  \def\@noitemerr{\@latex@warning{Empty `thebibliography' environment}}%
  \endlist
}
\makeatother

\begin{document}

\title{Finding Lower Bounds for the Number of Comparison in Selection Algorithms}

\author{Josua Dörrer, Konrad Gendle, Johanna Hofmann, Julius von Smercek, Andreas Steding% <-this %
  \IEEEcompsocitemizethanks{\IEEEcompsocthanksitem Institut für Formale Methoden der
    Informatik (FMI)\protect\\
    Universität Stuttgart
  }}

\markboth{Bachelor-Forschungsprojekt}%
{Submission}

\IEEEtitleabstractindextext{%
  \begin{abstract}
    This research project aims to find worst case optimal comparison algorithms for selecting the
    i-th smallest of n elements of a set for n up to 15 with computer search.
  \end{abstract}

  \begin{IEEEkeywords}
    Selection, Pessimistic lower Bound, Partial Order Sets, Computer Search
  \end{IEEEkeywords}}


\maketitle

\IEEEdisplaynontitleabstractindextext


\IEEEpeerreviewmaketitle

\IEEEraisesectionheading{
  \section{Motivation}
  \label{sec:motivation}
} \IEEEPARstart{T}{he} problem of selecting the $i$-th smallest element in a list of $n$ elements is
a well known problem in computer science and called \textit{selection}. Explicitly, we
concern ourselves with optimal worst-case selection of a single element from a set of
initially unordered unique others, measuring the cost as number of comparisons made.
A first approach to solve
this can be achieved by sorting the list at first and selecting the $i$-th element. However, this
approach has a time complexity of $\mathcal{O}(n \cdot \log n)$. Putting more thought into this
problem one can find algorithms like the median of medians (Schöning \cite{Schoening1993}) or PICK
(Blum \cite{Blum1972}) and reduce the time complexity to $\mathcal{O}(n)$. Optimal algorithms are
known for any $n$ when $i$ is either one or two, but there is a significant performance gap finding
the median $i = \nicefrac{n}{2}$ from the best known algorithm with a time complexity of $2.97 \cdot
  n + \smallO(n)$ to the tightest known minimum of $2 \cdot n - \smallO(n)$.

Searching for optimal solutions is considerably difficult and the tightest known lower bounds
obtained by mathematical means soon exceed what is attainable by even rather intelligent search. An
approach to finding optimal algorithms is made by Gasarch, Kelly and Pugh \cite{Gasarch1996} who
introduced computer search to find optimal selection algorithms. On his website Kenneth Oksanen
\cite{Oksanen} published a computer search algorithm improving the previously known lower bounds
found by Gasarch et. al. However, the results are not published in a scientific journal and lack
explanation. This work will continue the work of Oksanen \cite{Oksanen} by confirming, improving and
expanding the values he found. It will reimplement some ideas of the algorithms Oksanen published
along with his found lower bounds and improve the computer search algorithms by researching the
benefits of different search strategies, adding $\alpha$-$\beta$-pruning and the exploitation of
compatible Posets. A quote from Miguel de Cervantes from Don Quijote will hold true for this
article: The journey is better than the inn. So buckle up.

\section{Fundamentals}
\subsection{Algorithms for Finding the $i$-th largest of $n$ elements}
\subsubsection{Sorting}
A baseline algorithm to select the $i$-th element in a list of $n$ values is to use a sorting
algorithm like merge sort or heap sort on the input data and then return the $i$-th element of the
now sorted list. The time complexity of this approach is essentially the runtime to sort the list.
For the sorting algorithms mentioned the time complexity is of $\mathcal{O}(n \cdot \log n)$

\subsubsection{Pivoting}
A better approach solving the selection problem can be achieved by using pivoting. The common idea
of the algorithms using pivoting is to promote an element from the input to a so called
\textit{pivot} element and use comparisons against this element to divide the remaining $n-1$ input
elements into two subsets. Let $L$ be the subset with elements less then the pivot element and $G$
the subset with elements greater than the pivot element. The algorithm can then determine whether to
search for the $i$-th element in the subset $L$ or the subset $G$. Using pivot algorithms like
Floyd-Rivest algorithm, a variation of quickselect, the runtime can be reduced to
$\mathcal{O}(\sqrt{n \cdot \log n})$. The first linear-time deterministic selection algorithm known
is  also commonly taught in computer science class is the median of medians. It partitions the input
data into sets of five in linear time. Then it calls itself on each of the sets to find the median
of these sets of five. The result is a algorithm that returns the median in $\mathcal{O}(n)$. In
practice the algorithm performs poorly compared to quickselect and is also slower than sorting the
list of moderate size due to its high constant factor. Better algorithms like quickselect or PICK
have a lower constant factor but all these algorithms share the same time complexity
$\mathcal{O}(n)$.
\todo{hier fehlt ein cite}
% https://en.wikipedia.org/wiki/Selection_algorithm#cite_note-knuth-14

\subsubsection{Lower and upper bounds}
The time complexity of $\mathcal{O}(n)$ of the mentioned algorithms is inevitable, because the input
to these algorithm is a list of values in arbitrary order. Therefore, the algorithm must look at all
the input values to determine a correct solution. If any of these input values will not be
considered it could be the one that should have been returned by the algorithm leading to wrong
results. Apart from this simple and straightforward argument, there is a considerable amount of
research on the exact number of comparisons required for selection, both in the randomized and
deterministic cases.

It has been found that selecting the $i$-th element of $n$ requires at least
$n+\min(i,n-i)-\mathcal{O}(1)$ comparisons, thus matching the average case of the Floyd-Rivest
algorithm up to his $\smallO(n)$ term. For deterministic algorithms it has also been shown that
\begin{eqnarray*}
  &\left (1 + H(i/n) \right ) \cdot n + \Omega(\sqrt n) \\
  &\text{with~} H(x) = x \cdot \log_2 \frac{1}{x} + (1-x) \log_2 \frac{1}{1-x}
\end{eqnarray*}
are required. An upper bound is been proposed by Blum, in the paper \textit{Time Bounds for
  Selection}. It stated that no more than $5.430\dot{5} \cdot n$ comparisons are ever required.
Therefore selection is for sure in a time complexity of $\mathcal{O}(n)$ for best and worst-case.

\begin{lemma}
  If $k$ is a lower bound for selecting $i$ of $n$, then selecting $i$ of $n+1$ must take at least $k+1$ comparisons.
\end{lemma}
\begin{proof}
  Assume some algorithm exists that selects $i$ of $n+1$ in $k$ comparisons. It must have two elements it compares first.
  If we input a by definition largest element in place of one of them the algorithm must still return the correct $i$-th
  largest of the remaining $n$ elements. But because this element is larger by definition, the first comparison may be
  skipped, thus reducing the number of comparisons by at least 1. Thus taking out all occurrences of that element will
  yield an algorithm for $i$ of $n$ in $k-1$ comparisons, which contradicts the condition of $k$ being a lower bound.
\end{proof}

\subsection{Partial Order Sets}
To dive deeper into these algorithms the concept of partial orders needs to be introduced. A partial
order is an ordering relation
$\leq$ on a set $P$ that satisfies reflexivity, anti symmetry, and transitivity.

\begin{definition}[Selection Poset]
  Given a set of elements $\Omega$ with $|\Omega| = n < \infty$ we write
  $(n, i, R)$ for the selection of the $i$-th largest of $n$ elements
  with the existing comparisons $R$.
  Explicitly, $R\subseteq\Omega^2$ such that $(a, b)\in R \Longleftrightarrow a \leq b$.

  The enumeration of $i$ starts at $0$, so $(4, 1, R)$ is the second smallest,
  rather than the minimum.
\end{definition}

The SELECT problem is thus embedded as $(n, i, \emptyset)$.

\begin{definition}[Reduced]
  A poset is \textbf{Reduced} if all of its elements have less than $i-1$ elements smaller than themselves and less than $n-1$ larger. Hence, all elements are still possible solutions.
\end{definition}
\begin{definition}[Canonified]
  A poset is \textbf{Canonified} if it matches the following conditions making it unique among all posets isomorphic to it:
  \begin{itemize}
    \item % TODO Absatz sec:backward:normal_form verlinken
  \end{itemize}

  Some parts of this paper use a best effort
  approximation for this to increase speed, the results are then called \textbf{Pseudo Canonified}.
\end{definition}
\begin{definition}[Normal]
  A \textbf{Normal} poset is reduced and canonified.
\end{definition}

\begin{definition}[Optimal Cost]
  The cost $V(P)$ of the poset $P = (n, i, R)$
  is the optimal number of further comparisons needed to
  perform the selection.

  We measure this pessimistically, meaning that among all
  possible outcomes of those further comparisons we assume
  the most expensive ones.
\end{definition}

\begin{definition}[Dual Poset] \label{definition:inverse_poset}
  The dual of a poset $P=(n, i, R)$ is the poset $P^{-1}=(n, n-1-i, R')$ with $R' = \{(u,v) \; \vert \; (v,u) \in R\}$.
\end{definition}

\begin{lemma}
  For a given poset $P = (n, i, R)$ $V(P) = V(P^{-1})$
\end{lemma}

\begin{proof}
  Given $V(P)$, we know that we can construct an algorithm that
  solves $P$ in exactly that many comparisons, i.e. it determines
  the element with exactly $i-1$ less and exactly $n-i$ greater
  than itself.

  Since $n$ and $i$ are fixed, this algorithm can be converted into
  a binary decision tree and by swapping all the children, the new
  algorithm must now select the element such that $n-i$ are smaller
  and $i-1$ are larger than it while assuming an inverted $R$, which is
  the solution for $P^{-1}$.
\end{proof}

%[\todo{cite:https://en.wikipedia.org/wiki/Partially_ordered_set}]

\subsubsection{Solved Posets and Compatible Solutions}
By definition of the problem, we seek an
element that is larger than $n-i$ elements and smaller than
$i-1$ elements.

\begin{lemma}\label{lemma:partition}
  Solving a poset requires knowing the explicit elements
  making up these two sets.
\end{lemma}
\begin{proof}
  Suppose we have determined the element $e$ to be the
  solution, and an element $p$ unordered with $e$.

  Then $p$ may be above as well as below $e$, which
  can't be the solution in both cases.
\end{proof}

\begin{definition}[Compatible Solution]
  As such we can define a \textbf{Compatible Solution} $Q = (n, i, S)$ of a poset $P=(n, i, R)$, to be solved and agreeing with $P$, that is $(a, b)\in S\implies (b, a)\notin R$.

  Furthermore, $Q$ has no comparisons other than the $n-1$ needed to prove
  the solution and the ones resulting from application of transitivity to the former.
\end{definition}

With Lemma \ref{lemma:partition}, a solved poset has exactly one compatible solution.

Let $$\mathcal{C}(P) = \{Q \mid Q \text{ compatible with } P\}$$ be the set of all posets compatible with $P$.

\begin{lemma}\label{lemma:compatible_union}
  For a Poset $P = (n, i, R)$ and $a, b$, $(a,b), (b,a)\notin R$
  $\mathcal{C}(P) = \mathcal{C}(n, i, R\cup \{(a, b)\}) \cup \mathcal{C}(n, i, R\cup \{(b, a)\})$.
\end{lemma}
\begin{proof}
  Let $Q = (n, i, S)\in \mathcal{C}(P)$. Then for all $c, d$ other than $a, b$ it must hold that $(c,d)\in S\implies (d,c)\notin R\cup \{(a, b)\}$ and $(c,d)\in S\implies (d,c)\notin R\cup \{(b, c)\}$.

  So if $(a, b)\in S$ then $Q\in\mathcal{C}(n, i, R\cup \{(a, b)\})$,
  if $(b, a)\in S$ then $Q\in\mathcal{C}(n, i, R\cup \{(b, a)\})$
  and if $a, b$ are unordered in $Q$, it is in both.

  The reverse also holds because $(c,d)\notin R\cup \{(a, b)\}\implies (c,d)\notin R$, same for $R\cup \{(b, a)\}$.
\end{proof}

\begin{theorem}
  A poset $P=(n,i,R)$ cannot be solvable in less than $\lceil\log_2(|\mathcal{C}(P)|)\rceil$ comparisons in the worst case.
\end{theorem}
\begin{proof}
  If $P$ is already solved, $|\mathcal{C}(P)|=1$, and $\log_2(1)=0$.

  If not, we must make at least one more comparison $a, b$.

  From Lemma \ref{lemma:compatible_union} we also know that
  $$|\mathcal{C}(P)| \leq |\mathcal{C}((n,i,R\cup \{(a, b)\}))| + |\mathcal{C}((n,i,R\cup \{(b, a)\}))|$$

  Since this is a pessimistic measure, we must assume that the result of the comparison
  results in the one with more compatible solutions. Without loss
  of generality we assume that to be $(a, b)$. Then

  $$\frac{|\mathcal{C}(P)|}{2}\leq |\mathcal{C}((n,i,R\cup \{(a, b)\}))|$$

  Repeated application of this over multiple comparisons results in
  $\frac{|\mathcal{C}(P)|}{2^j}$
  as the lower bound for the amount of compatible posets
  after $j$ comparisons.

  Since $\mathcal{C}(P)|\leq 2^j$ must be satisfied for the solution, $j\geq\log_2(|\mathcal{C}(P)|)$
\end{proof}


\subsection{Example}
\begin{figure}[h!]
  \centering
  \input{figures/tikz_example_5_2.tex}
  \caption{Finding the median $i=2$ of $n=5$ values using six comparisons.}
  \label{fig:median_of_5}
\end{figure}
A good visual example is finding the median $i=2$ in a list of $n=5$ elements. Figure
(\ref{fig:median_of_5}) illustrate the search of the median using Hasse diagrams. Each step shows
the comparisons to be performed next as a yellow line. A Hasse diagram of the order of relation
found so far (smaller=lower, larger=higher) is shown as the blue lines. The red circles have already
found to be greater than three others and disqualified The red elements have already been determined
to be larger than three other elements and are therefore disqualified as medians. The larger
element of the final comparison is the median. This is also the optimal algorithm for $i=2$ and
$n=5$.


\section{Methods and Tools}
In this section we describe our three main approaches being the forward search, backward search and bidirectional search. Furthermore, we explain how we harness the notion of compatible posets with respect to all of the three search approaches.

\subsection{Forward Search}\label{chapter:forward_search}
Forward Search starts with an empty Poset, i.e. one with entirely unknown ordering of its elements,
and recursively determines solvability of a given Poset within some bound by exhaustively searching
the results of all possible comparisons to be made unless it is already solved or we determine that
it cannot be solved within the alloted number of comparisons by some heuristic.

Between the two possible outcomes of a comparison we assume the worse, but since an algorithm is
free to choose which elements to compare we are looking for the most useful comparison, the one that
yields result Posets cheapest to solve themselves, still in terms of worst case outcome. The
algorithms output by the search program are built by saving the comparison that lead to this
cheapest to solve result.

To limit memory cost and allow further pruning we traverse the search tree depth first, reducing the
maximum number of comparisons alloted to child Posets to one less than the current best result
found. This premise is implemented by Minimax algorithms as shown in
figure~\ref{fig:minimax_search}.

We can drastically speed up this exploration by caching previous results, even with a simple usage
based ejection policy. Since the search always imposes an upper bound for the number of comparisons
to allow this also includes yet unsolved Posets, for which we note the currently known minimum.

The minimax search algorithm also allows for cutting off unpromising branches. For this means, and inspired by the idea of $\alpha$-$\beta$-pruning, two strategies are applied.
Firstly, we use a so called solvable-heuristic.
The heuristic is employed to estimate whether a poset is solvable. If the heuristic's estimate states 'unsolvable', the branch is pruned.
Otherwise, the search continues regularly.
Secondly we use a measure called \texttt{current\_best}.
Each call of \texttt{search\_rec} gets a maximum numbers of comparisons. When searching the children of a node, the limit is the best (minimal) value found so far.

It is optimal because of an inductive argument over the number of relative orders determined. An
already solved Poset obviously takes no further comparisons to solve. Then, given an unsolved Poset
with all elements already too large or small excluded we must make at least one more comparison to
make progress. Since all Posets resulting from these comparisons must have more elements ordered
than the current one has we can assume as per induction that we know their optimal cost. As a result, we
cannot solve the Poset in less than the cost of the cheapest of these comparisons, plus one for the
comparison itself, hence the current Poset is also solved optimally.

It is also complete for a given upper bound, explainable through a similar inductive argument. If
the Poset is solvable within that bound, then at least one of its possible comparisons must have both
outcomes be solvable within the bound lowered by one. Since the search only lowers the bound imposed
on its recursive descendants beyond that once at least one has been solved, we are also guaranteed
to find a solution for the original Poset if it exists within the bound.

\begin{figure}
  \input{figures/tikz_minimax_search_algorithm.tex}
  \caption{Minimax search algorithm}
  \label{fig:minimax_search}
\end{figure}

\subsubsection{Canonification}

When caching the posets we have to check, whether two posets are isomorphic to each other.
We consider a poset isomorphic to another poset if we can relabel the elements of one poset to obtain the other poset.
This problem is expensive to solve for every poset comparison.

After adding a comparison to a poset, we transform the poset to a canonical form.
All posets, that are isomorphic to each other should be transformed to the same canonical form.
Computing the canonical form can be done using Nauty, but this takes a significant amount of time.
Some performance tests show that it is faster to compute an almost canonical form, where some posets that are isomorphic to each other result in different canonified forms.
As a result, some posets that are isomorphic occupy several cache entries, but canonifying a poset is much faster.

\subsection{Backward Search} \label{sec:backward}

Backward search starts with a solved poset, then repeatedly attempts to remove comparisons from its
frontier posets such that the same poset with the opposite comparison result is also found within
those already discovered.

Thus, the number of iterations taken until a poset is added to the frontier equals the number of
worst case comparisons needed to solve it, which means that the search terminates once the empty
poset with the desired $n$ and $i$ is found.

The argument for correctness is that the number of comparisons for which we have found all posets solvable within them equals the number of iterations of the search.
If for a given poset and a comparison within it we have already discovered both results then their cost must be less than the current number of iterations. Hence, we can conclude that the poset is solvable within this number of comparisons.
Since this condition did not hold true in any previous iteration, we can further infer that the cost must also be optimal.
And if a poset is solvable within
that number of comparisons it must have at least one comparison with a result among the Posets
discovered in the previous iteration, as otherwise it would have to be solvable in less.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% TODO: In Papern suche, ob die Rückwärtssuche wirklich komplett neues Gebiet ist

\subsubsection{Normalform} \label{sec:backward:normal_form}

In contrast to the forward search, the backward search uses a unique canonicalization. % TODO: 
The canonicalization of the forward search is not unique for performance reasons.

\subsubsection{Normalform}
Note that the backward search requires a unique normal form. In case our custom canonification does not yield a unique form, nauty provides the proper canonification.
In the following, the canonification process is explained.

First, it is determined whether $i < n-1-i$ holds.
If this does not hold true, $P$ is replaced by $P^{-1}$.
According to lemma~\ref{lemma:inverse_poset} the poset's solvability remains unaltered.

Finally, the poset's elements are arranged canonically.
As a means to this end, the poset is represented as a directed graph with respect to its Hasse diagram.
The canonic labelling of the elements is provided by nauty, which is a program in C for the calculation of graph automorphism groups \cite{MCKAY201494}.
With this canonic labelling the poset can be portrayed canonically.
A potential problem occurs, if $i = n - 1 - i$ holds.
In this case, it is impossible to decide whether $P$ or $P^{-1}$ corresponds to
to the canonical normal form based on the value of $i$.

\begin{figure}
  \input{figures/tikz_backward_canonify_problematic.tex}
  \centering
  \caption{Problematischer Fall}
  \label{fig:backward_canonify_problematic}
\end{figure}

In the Hasse diagram in figure~\ref{fig:backward_canonify_problematic} the posets appear unidentical, despite them being each others inverse.
To mitigate th
In order to eliminate this ambiguity, the inverse is also calculated and canonicalized for each poset for which $i = n - 1 - i$ applies.
One of the two is then selected deterministically.

Since canonification is inevitable for the backward search but takes up a large portion of the computing time, all trivial cases are treated manually and only the remaining cases are canonified by nauty.

The manual canonification works as follows.
First, the in- and out degree is calculated for each nodes.
Based on these values a hash value is assigned to each node.
The hash also takes into account the topological structure of all adjacent nodes recursively upto a certain recursion depth limit.

Then, the nodes are sorted according to their in- and out degree and their hash value.
If each degree and each hash value is unique the graph finally attained its unique normal form.
For two nodes having identical attributes, it is attempted to swap them.
If the representation remains unchanged, the poset is regarded as uniquely canonified, since both graphs map to the same representation.
If the representations differ, the graph is treated as follows.
Let there be $l$ pairs of nodes with the same attributes, respectively.
The algorithm iterates over all possible permutations.
For the first pair there are two possibilities: Either the nodes are swapped, or they remain unchanged.
Under the realistic assumption of $l$ being small, all possible $2^l$ possible permutations can be efficiently iterated.
Finally, one permutation is selected deterministically based on its representation.

Applying this canonification preprocessing reduces the cases requiring nauty drastically, as shown in table~\ref{table:nauty-ratio} for $n=13$.

It is particularly noteworthy that for higher $i$, the percentage of nauty calls declines.
For small values of $i$, the high percentage of nauty is uncritical, as the result for small $i$ can be calculated quickly anyway.
\begin{table}
  \begin{tabular}{l|l}
    $i$ & nauty-Ratio \\
    \hline
    $0$ & $0.000\%$   \\
    $1$ & $30.205\%$  \\
    $2$ & $6.797\%$   \\
    $3$ & $1.530\%$   \\
    $4$ & $0.469\%$   \\
    $5$ & $0.188\%$   \\
    $6$ & $0.116\%$
  \end{tabular}
  \centering
  \caption{Prozentuale Häufigkeit der Aufrufe von nauty zur Kanonisierung für $n = 13, i = 6$}
  \label{table:nauty-ratio}
\end{table}

\subsubsection{Algorithmus} \label{sec:backward:algorithm}
% Schreibweise: $\text{P}^{n, i}$
% select(n, i)

Die Eingabe für die Rückwärtssuche sind die Parameter $n$ und $i$.
Die Rückwärtssuche beginnt mit dem kleinsten gelösten Poset und berechnet iterativ alle Posets, die in $1, 2, 3, \dots$ Vergleichen gelöst werden können, bis das leere Poset mit $n$ Elementen und dem $i$-kleinsten gesuchten Element gefunden wird.
Das kleinste gelöste Poset besteht aus einem Element und enthält keine Vergleiche.
Das leere Poset besteht aus $n$ Elementen, wobei das $i$-kleinste Element gesucht wird, und beinhaltet keinen Vergleich.
Allgemein sei $A_k$ die Menge aller Posets, die in $k$ Vergleichen lösbar sind.
$A_0$ besteht nur aus dem kleinsten gelösten Poset.
Im Folgenden berechnet die Rückwärtssuche für jedes Poset in der Menge $A_k$ die entsprechenden Vorgänger.
Die Menge aller Vorgänger bildet die Menge $A_{k + 1}$.
Wenn das leere Poset mit $n$ Elementen und dem $i$-kleinsten gesuchten Element in $A_l$ vorhanden ist, werden genau $l$ Vergleiche benötigt, um das $i$-kleinste Element einer $n$-elementigen Liste zu bestimmen.

\subsubsection{Predecessor calculation} \label{sec:backward:predecessor_calculation}

\begin{definition}[Predecessor] \label{definition:predecessor_calculation}
  Poset $q$ is the predecessor of Poset $p$ if the following conditions hold:
  \begin{itemize}
    \item poset $q$ is reduced and canonified
    \item poset $q$ was not found in any previous round (otherwise it would be solvable in fewer comparisons)
    \item There exists a comparison $(i, j)$ whose adding in $q$ and subsequent normalization results in the poset $p$ and adding the reverse comparison $(j, i)$ and subsequent normalization results in an already found poset.
  \end{itemize}
\end{definition}

\begin{lemma} \label{lemma:predecessor_calculation}
  If poset $p$ is solvable in $k$ comparisons and $q$ is a predecessor of poset $p$, poset $q$ is solvable in $k + 1$ comparisons
\end{lemma}

\begin{proof} \label{proof:predecessor_calculation}
  Since $q$ was not found in any previous round, according to the assumption, it is not solvable in fewer comparisons.
  By performing the addition of comparison $(i, j)$ followed by normalization, the poset $p$ is derived, consequently establishing the reachability of $q$.
  As $p$ is solvable in $k$ comparisons, thus $q$ is solvable in $k + 1$ comparisons.
  If the comparison is inserted in reverse, according to the assumption, the resulting poset is already in the cache.
  Thus, this path is solvable in at most $k + 1$ comparisons.
\end{proof}

Since potentially infinitely many predecessors exist, only up to a maximum limit of $n_{\text{max}}$ elements are computed.
The computation of a predecessor for a given poset $p = (n_p, i_p, R_p)$ proceeds in four steps:

\begin{itemize}
  \item[1.]
    Firstly, we search for all posets with $n_p$ elements that result in poset $p$ after inserting a comparison followed by canonification.

    A challenge arises from transitive comparisons, as the insertion of one comparison can result in the insertion of multiple transitive comparisons.

    \begin{figure}
      \centering
      \input{figures/tikz_problematic_case.tex}
      \caption{Case in which further comparisons could be removed transitively by removing a comparison}
      \label{fig:backward_problematic}
    \end{figure}

    As illustrated in Figure~\ref{fig:backward_problematic}, all three posets are fully reduced and canonized.
    Removing a comparison from Poset (1) can result in either Poset (2) or Poset (3).
    This implies that depending on the current cache, both Poset (2) and Poset (3) are valid potential predecessors, even though the same comparison is removed each time.

    To solve this problem, all potential predecessors must be computed.

  \item[2.]
    Im nächsten Schritt werden alle Vorgänger berechnet, die $n + 1$ Elemente haben und durch Einfügen eines Vergleichs gefolgt von einer Kanonisierung erneut das Poset $p$ ergeben.

    Da das neue Element kleiner oder größer als das gesuchte $i$-kleinste Element ist, wird bei diesen Vorgängern nach dem $i + 1$-kleinsten bzw. dem $i$-kleinsten Element gesucht.
    Da das Poset $p$ kanonifiziert ist, gilt $i \leq n - 1 - i$ für $p$.
    Durch das Kanonifizieren des Posets mit $n + 1$-Elementen und dem $(i + 1)$-kleinsten gesuchten Element, kann es hier jedoch nötig sein das Inverse Poset zu bilden wodurch das $(n + 1) - (i + 1) - 1 = n - i + 1$-te Element gesucht ist.

    Hierfür wird in Poset $p$ ein neues Element sowie passende Vergleiche eingefügt.
    Passende Vergleiche bedeutet, dass das neue Element nicht unmittelbar wegreduziert werden darf und es noch einen Vergleich gibt, der eingefügt werden könnte, ohne dass das neue Element wegreduziert werden kann, nach Lemma~\ref{lemma:remove_only_last_element_edge}.

    \begin{lemma} \label{lemma:remove_only_last_element_edge}
      Um alle möglichen Vorgänger mit $n + 1$ Elementen zu konstruieren, müssen nur Vergleiche zwischen dem neuen Element und beliebig vielen anderen Elemente hinzugefügt werden.
    \end{lemma}

    \begin{proof} \label{proof:remove_only_last_element_edge}
      Angenommen, es existiert ein Vorgänger mit $n + 1$ Elementen, bei dem das $(n + 1)$-te Element wegreduziert werden kann, wenn ein Vergleich zwischen dem $i$-ten und dem $j$-ten Element eingefügt wird, wobei $0 \leq i < j \leq n$.
      Dann ... % TODO: idk
    \end{proof}

    Anschließend werden die Posets aus dem 1. und 2. Schritt in einer Menge zusammengeführt und es wird sichergestellt, dass alle Posets kanonisiert sind.
    Bezeichne den Vergleich, der eingefügt werden könnte, ohne das ein Element wegreduziert werden kann im folgenden als den entfernten Vergleich.

  \item[3.]
    Im dritten Schritt wird für jedes bereits gefundene Element iterativ neue Elemente eingefügt, bis die obere Grenze $n_{\text{max}}$ erreicht ist.
    Wenn ein neues Element eingefügt wird, muss beachtet werden, dass eventuell nicht mehr das $i$-kleinste, sondern das $(i + 1)$-kleinste Element gesucht wird, genau wie im 2. Schritt, und das neue Element nicht direkt wegreduziert werden kann.
    Des Weiteren muss durch das Einfügen im 1. und 2. Schritt entferten Vergleichs und anschließendem reduzieren sowie kanonifizieren wieder Poset $p$ resultieren.

  \item[4.]
    Im letzten Schritt wird für jeden Vorgänger die minimale Anzahl an Vergleichen berechnet, die noch entfernt werden müssen, bis das leere Poset erreicht ist.
    Diese Anzahl entspricht den Kanten im zugehörigen Hasse-Diagramm.
    Anhand der bekannten theoretischen oberen Schranken können alle Posets verworfen werden, die zu viele Vergleiche enthalten, da diese zu keinem leeren Poset in den verbleibenden Vergleichen führen können und somit auch in der Vorwärtssuche nicht betrachtet werden können.
\end{itemize}

Da die theoretischen oberen Schranken in der Praxis zu hoch sind, verwendet das Programm einen iterative deepening-Ansatz.
Dieser beginnt mit einer oberen Grenze, die der theoretischen unteren Schranke entspricht, und erhöht diese Grenze iterativ, bis schließlich eine Lösung gefunden wird.
Obwohl dieser Ansatz dazu führt, dass die Rückwärtssuche mehrfach neu gestartet wird, da keine Ergebnisse aus vorherigen Runden übernommen werden können, kann dadurch der Suchraum erheblich eingeschränkt werden.

\begin{figure}[h!]
  \centering
  \includegraphics[width=\columnwidth]{figures/backward-search-tree.png}
  \caption{Suchbaum für $n = 4, i = 1$, k gibt Anzahl Vergleiche. Die Rückwärtssuche startet bei dem leeren Poset in $k = 0$. \\
    ganzer Pfeil: gibt direkt einen Vorgänger an
    gestrichelter Pfeil: wenn der "umgedrehte" Vergleich eingefügt wird}
  \label{fig:backward-search-tree}
\end{figure}

\begin{figure}
  \centering
  \input{figures/tikz_posets_per_level.tex}
  \caption{Number of comparisons required to solve the empty poset with the backward search for $n = 14$ depending on $i$}
  \label{fig:backward-posets-per-level}
\end{figure}

\subsubsection{Parallelisierung} \label{sec:backward:parallelisation}
Die Rückwärtssuche kann effizient parallelisiert werden, indem die Berechnung der Vorgänger parallel durchgeführt wird.

\begin{table}
  \begin{tabular}{l|r|l}
    number cores & time      & efficiency \\
    \hline
    $1$          & 7h 2m 59s & $1.000$    \\
    $4$          & 2h 41s    & $0.877$    \\
    $8$          & 1h 2m 9s  & $0.851$    \\
    $32$         & 20m 11s   & $0.655$    \\
  \end{tabular}
  \centering
  \caption{Efficiency of parallelism for $n = 13, i = 6$ (note: the drop in efficiency can be partly explained by the shared use of the server)}
  \label{table:backward-parallel}
\end{table}

Wie in Tabelle~\ref{table:backward-parallel} für $n = 13, i = 6$ dargestellt, skaliert die Rückwärtssuche relativ gut mit der Anzahl der Kerne.
Die Effizienz ist hierbei zwischen 0 und 1.
Umso höher der Wert, desto besser die Paralleisierung.
Die Effizienz kann wie folgt berechnet werden:
\[
  \text{Effizienz} = \cfrac{\text{single-core time}}{\text{number of cores} \cdot \text{multi-core time}}
\]

\subsection{Bidirektionale Suche} \label{sec:bidirectional}

Bei der bidirektionalen Suche werden sowohl die Vorwärts- als auch Rückwärtssuche gleichzeitig gestartet.
Es ist zu beachten, dass die Rückwärtssuche mit der theoretischen oberen Schranke gestartet wird und nicht den iterativen deepening-Ansatz verwendet, wie es bei der reinen Rückwärtssuche der Fall ist.
Während der Rückwärtssuche werden alle bereits gefundenen Posets in einem globalen Cache gespeichert und zusätzlich bis zu welcher Ebene der Cache vollständig ist, das heißt, in welcher Ebene sie sich derzeit befindet.
Diese Ebene sei im Folgenden als $k$ bezeichnet.
Die Vorwärtssuche wird abgebrochen, wenn höchstens $k$ Vergleiche übrig sind und gibt die genaue Grenze zurück, falls sich das Poset im Cache der Rückwärtssuche befindet.
Andernfalls wird zurückgegeben, dass mindestens $k + 1$ Vergleiche erforderlich sind.

\begin{figure}[h!]
  \input{figures/tikz_backward_forward_13_6.tex}
  \centering
  \caption{Anzahl Posets vs. Anzahl Vergleiche für $n=13, i=6$ (rot: Rückwärtssuche, blau: Vorwärtssuche)}
  \label{fig:backward_forward_count_13_6}
\end{figure}

Wie in Abbildung~\ref{fig:backward_forward_count_13_6} zu sehen, durchsucht die Vorwärtssuche für $n = 13, i = 6$ die meisten Posets bei $k = 6$ Vergleichen, während die Rückwärtssuche die meisten Posets bei $k = 14$ durchsucht.
Dies ist sehr unvorteilhaft für eine bidirektionale Suche, da der Großteil des Suchraums vor dem Treffpunkt beider Suchen liegt.

% TODO: Ergebnisse der Bidirektionalen Suche vorstellen

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Pruning Decisions}
The minimax search algorithm explained in chapter~\ref{chapter:forward_search} allows for cutting off unpromising branches. For this means, the following strategies are applied.

\begin{enumerate}
  \item[1.]
    Use solvable-heuristic. A heuristic is employed to estimate whether a poset is solvable. If the heuristic's estimate states 'unsolvable', the branch is pruned.
    Otherwise, the search continues regularly.
  \item[2.]
    Use \texttt{current\_best}. Each call of \texttt{search\_rec} gets a maximum numbers of comparisons.
    When searching the children of a node, the limit is the best (minimal) value found so far.
\end{enumerate}

\section{Results}

\begin{table}
  \centering
  \begin{tabular}{c|cccccccc}
    $n$ & \multicolumn{8}{c}{$i$}                                    \\
        & 0                       & 1  & 2  & 3  & 4  & 5  & 6  & 7  \\ \hline
    1   & 0                                                          \\
    2   & 1                                                          \\
    3   & 2                       & 3                                \\
    4   & 3                       & 4                                \\
    5   & 4                       & 6  & 6                           \\
    6   & 5                       & 7  & 8                           \\
    7   & 6                       & 8  & 10 & 10                     \\
    8   & 7                       & 9  & 11 & 12                     \\
    9   & 8                       & 11 & 12 & 14 & 14                \\
    10  & 9                       & 12 & 14 & 15 & 16                \\
    11  & 10                      & 13 & 15 & 17 & 18 & 18           \\
    12  & 11                      & 14 & 17 & 18 & 19 & 20           \\
    13  & 12                      & 15 & 18 & 20 & 21 & 22 & 23      \\
    14  & 13                      & 16 & 19 & 21 & 23 & 24 & 25      \\
    15  & 14                      & 17 & 20 & 23 & 24 & 26 & 26 & 27 \\
  \end{tabular}
  \caption{The minimum amount of comparisons needed to select the $i+1$-th smallest of $n$}
  \label{table:num-comparisons}
\end{table}

See Table~\ref{table:num-comparisons}.


\begin{table}[htbp]
  \begin{tabular}{c|c|l|l}
    \textbf{n} & \textbf{k} & \textbf{Forward Search } & \textbf{Backward Search } \\ \hline
    12         & 0          & 0.0s                     & 0.0s                      \\
    12         & 1          & 0.0s                     & 0.1s                      \\
    12         & 2          & 0.3s                     & 0.7s                      \\
    12         & 3          & 3.5s                     & 1.6s                      \\
    12         & 4          & 59.1s                    & 8.4s                      \\
    12         & 5          & 3m 11.0s                 & 42.0s                     \\
    \hline
    13         & 0          & 0.0s                     & 0.0s                      \\
    13         & 1          & 0.0s                     & 0.5s                      \\
    13         & 2          & 0.4s                     & 1.5s                      \\
    13         & 3          & 13.8s                    & 16.1s                     \\
    13         & 4          & 5m 35.8s                 & 1m 40.2s                  \\
    13         & 5          & 35m 14.0s                & 8m 34.7s                  \\
    13         & 6          & 1h 24m 51.8s             & 18m 4.8s                  \\
    \hline
    14         & 0          & 0.0s                     & 0.0s                      \\
    14         & 1          & 0.0s                     & 1.5s                      \\
    14         & 2          & 0.4s                     & 5.9s                      \\
    14         & 3          & 22.5s                    & 46.9s                     \\
    14         & 4          & 19m 36.8s                & 15m 32.5s                 \\
    14         & 5          & 3h 53m 26.4s             & 1h 39m 59.6s              \\
    14         & 6          & 18h 57m 26.1s            & 6h 26m 30.8s              \\
    \hline
    15         & 0          & 0.0s                     & 0.0s                      \\
    15         & 1          & 0.0s                     & 4.0s                      \\
    15         & 2          & 0.6s                     & 25.9s                     \\
    15         & 3          & 1m 14.8s                 & 13m 10.9s                 \\
    15         & 4          & 1h 17m 55.0s             & 45m 51.9s                 \\
    15         & 5          & 1d 16h 41m 26.0s         & 19h 30m 20.6s             \\
    15         & 6          & 12d 13h 43m 26.9s        & tbd.                      \\
    15         & 7          & 14d 1h 50m 45.3s         & tbd.                      \\
  \end{tabular}
  \centering
  \label{tab:search_algorithms}
  \caption{Comparison of the times for the forward and backward search (note: the forward search runs single threaded, in contrast to the backward search which benefits greatly from parallelism)} % TODO: Verweis auf Hardware einfügen
\end{table}


\subsection{Search evaluation}
\subsubsection{Backward search}
\subsubsection{bidirectional search}
\subsubsection{forward search}

\subsection{Algorithmic improvements}

\subsubsection{Heuristics}

We used multiple heuristics to estimate if a poset is solvable in a given number of comparisons.
These heuristics are used to reject posets, that are not solvable in the given number of comparisons.
This reduces the number of posets that need to be searched.

The first heuristic uses the number of compatible posets.
We use the fact, that the number of comparisons needed to solve a poset is less than the base two logarithm of the number of compatible posets,
to estimate if a poset is solvable.

The second heuristic searches for two elements which have not been compared yet.
One of these two elements is maximal and has at least two elements smaller than it,
and the other element is minimal and has at least two elements greater than it.
We then construct a new poset with a comparison added, where the minimal element is smaller than the maximal.
The new poset is then searched for a solution using the forward search described above.
If the new poset is found to be solvable in the given number of comparisons, we estimate that the original poset is also solvable.
If the new poset is not solvable, we estimate the original is not solvable either.
This heuristic can be slightly improved by maximizing the number of elements smaller than the maximal element and greater than the minimal element.

\subsubsection{Triangular Adjacency Matrix}
Storing an adjacency matrix for a poset of size $n$ takes $n^2 - n$ bits, one for each possible relation.
The diagonal does not need to be stored, as an element can not be smaller than itself.

By canonifying the poset, the elements can be sorted in a way such that each element is not smaller than any element before it.
This property can be used to reduce the adjacency matrix to a triangular matrix, which can then be stored using $\frac{n^2 - n}{2}$ bits.
It can also simplify some algorithms, for example calculating the number of compatible posets.

\subsubsection{Multithreading}

\section{Conclusion}
Using computer search based on the work of Oksanen we were able to write our own
version of a search program for selecting the $i$-th element of a list of $n$
(see: \href{https://github.com/JGDoerrer/selection_generator}{Github}) not only
confirming the found solutions of Oksanen for the problem but also improving
some entries (e.g. $n=15, i=5$). Further we added some more numbers and
therefore algorithms to the table for higher $n$ and $i$. As stated in the
motivation before: the road is better than the inn. Along the way we learned a
lot about the probem structure and complexity, improved our forward and backward
search algorithms coming to a final conclusion that both are valid and have
their strength an weaknesses as stated in (\ref{}). If you want to use the
program to generate more optimal numbers and therefore algorithms one should
have quite some time and a good hardware in form of a high count CPU and as much
RAM as possible (see: \ref{} for our used hardware). Right now one should use
the backward search due to the lower RAM footprint and scaling with the CPU
count. If one is interested in continuing the journey the next steps would be to
add multithreading to the forward search and add the possibility of a
bidirectional search. Godspeed and all the best on your path.



\appendices
\section{Proof of the First Zonklar Equation}
Appendix one text goes here.
\section{}
Appendix two text goes here.


\ifCLASSOPTIONcompsoc
  \section*{Acknowledgments}
\else
  \section*{Acknowledgment}
\fi


The authors would like to thank...

FMI
Hardware
Florian Stober
Armin weiß

\ifCLASSOPTIONcaptionsoff
  \newpage
\fi


\bibliographystyle{IEEEtran}
\bibliography{biblio.bib}
\end{document}