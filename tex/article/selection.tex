\documentclass[10pt,journal,compsoc]{IEEEtran}

\usepackage[all,pdf]{xy}
\usepackage{tikz}




% *** CITATION PACKAGES ***
%
\ifCLASSOPTIONcompsoc
  % IEEE Computer Society needs nocompress option
  % requires cite.sty v4.0 or later (November 2003)
  \usepackage[nocompress]{cite}
\else
  % normal IEEE
  \usepackage{cite}
\fi

% *** MATH PACKAGES ***
%
\usepackage{amsmath}
\usepackage{todonotes}
\usepackage{nicefrac}
\usepackage{lmodern,amssymb}
\usepackage{float}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usetikzlibrary{positioning}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{pgfplots}
\usepackage{amsthm}

% Commands
\newcommand\smallO{
  \mathchoice
    {{\scriptstyle\mathcal{O}}}% \displaystyle
    {{\scriptstyle\mathcal{O}}}% \textstyle
    {{\scriptscriptstyle\mathcal{O}}}% \scriptstyle
    {\scalebox{.50}{$\scriptscriptstyle\mathcal{O}$}}%\scriptscriptstyle
  }

\interdisplaylinepenalty=2500


\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}

\hyphenation{op-tical net-works semi-conduc-tor ver-glei-che}

\makeatletter
\def\endthebibliography{%
  \def\@noitemerr{\@latex@warning{Empty `thebibliography' environment}}%
  \endlist
}
\makeatother

\begin{document}

\title{Finding Lower Bounds for the Number of Comparison in Selection Algorithms}

\author{Josua Dörrer, Konrad Gendle, Johanna Hofmann, Julius von Smercek, Andreas Steding% <-this %
  \IEEEcompsocitemizethanks{\IEEEcompsocthanksitem Institut für Formale Methoden der
    Informatik (FMI)\protect\\
    Universität Stuttgart
  }}

\markboth{Bachelor-Forschungsprojekt}%
{Submission}

\IEEEtitleabstractindextext{%
  \begin{abstract}
    This research project aims to find worst case optimal comparison algorithms for selecting the
    i-th smallest of n elements of a set for n up to 15 with computer search.
  \end{abstract}

  \begin{IEEEkeywords}
    Selection, Pessimistic lower Bound, Partial Order Sets, Computer Search
  \end{IEEEkeywords}}


\maketitle

\IEEEdisplaynontitleabstractindextext


\IEEEpeerreviewmaketitle

\IEEEraisesectionheading{
  \section{Motivation}
  \label{sec:motivation}
} \IEEEPARstart{T}{he} problem of selecting the $i$-th smallest element in a list of $n$ elements is
a well known problem in computer science and called \textit{selection}. Explicitly, we
concern ourselves with optimal worst-case selection of a single element from a set of
initially unordered unique others, measuring the cost as number of comparisons made.
A first approach to solve
this can be achieved by sorting the list at first and selecting the $i$-th element. However, this
approach has a time complexity of $\mathcal{O}(n \cdot \log n)$. Putting more thought into this
problem one can find algorithms like the median of medians (Schöning \cite{Schoening1993}) or PICK
(Blum \cite{Blum1972}) and reduce the time complexity to $\mathcal{O}(n)$. Optimal algorithms are
known for any $n$ when $i$ is either one or two, but there is a significant performance gap finding
the median $i = \nicefrac{n}{2}$ from the best known algorithm with a time complexity of $2.97 \cdot
  n + \smallO(n)$ to the tightest known minimum of $2 \cdot n - \smallO(n)$.

Searching for optimal solutions is considerably difficult and the tightest known lower bounds
obtained by mathematical means soon exceed what is attainable by even rather intelligent search. An
approach to finding optimal algorithms is made by Gasarch, Kelly and Pugh \cite{Gasarch1996} who
introduced computer search to find optimal selection algorithms. On his website Kenneth Oksanen
\cite{Oksanen} published a computer search algorithm improving the previously known lower bounds
found by Gasarch et. al. However, the results are not published in a scientific journal and lack
explanation. This work will continue the work of Oksanen \cite{Oksanen} by confirming, improving and
expanding the values he found. It will reimplement some ideas of the algorithms Oksanen published
along with his found lower bounds and improve the computer search algorithms by researching the
benefits of different search strategies, adding $\alpha$-$\beta$-pruning and the exploitation of
compatible Posets. A quote from Miguel de Cervantes from Don Quijote will hold true for this
article: The journey is better than the inn. So buckle up.

\section{Fundamentals}
\subsection{Algorithms for Finding the $i$-th largest of $n$ elements}
\subsubsection{Sorting}
A baseline algorithm to select the $i$-th element in a list of $n$ values is to use a sorting
algorithm like merge sort or heap sort on the input data and then return the $i$-th element of the
now sorted list. The time complexity of this approach is essentially the runtime to sort the list.
For the sorting algorithms mentioned the time complexity is of $\mathcal{O}(n \cdot \log n)$

\subsubsection{Pivoting}
A better approach solving the selection problem can be achieved by using pivoting. The common idea
of the algorithms using pivoting is to promote an element from the input to a so called
\textit{pivot} element and use comparisons against this element to divide the remaining $n-1$ input
elements into two subsets. Let $L$ be the subset with elements less then the pivot element and $G$
the subset with elements greater than the pivot element. The algorithm can then determine whether to
search for the $i$-th element in the subset $L$ or the subset $G$. Using pivot algorithms like
Floyd-Rivest algorithm, a variation of quickselect, the runtime can be reduced to
$\mathcal{O}(\sqrt{n \cdot \log n})$. The first linear-time deterministic selection algorithm known
is  also commonly taught in computer science class is the median of medians. It partitions the input
data into sets of five in linear time. Then it calls itself on each of the sets to find the median
of these sets of five. The result is a algorithm that returns the median in $\mathcal{O}(n)$. In
practice the algorithm performs poorly compared to quickselect and is also slower than sorting the
list of moderate size due to its high constant factor. Better algorithms like quickselect or PICK
have a lower constant factor but all these algorithms share the same time complexity
$\mathcal{O}(n)$.
\todo{hier fehlt ein cite}
% https://en.wikipedia.org/wiki/Selection_algorithm#cite_note-knuth-14

\subsubsection{Lower and upper bounds}
The time complexity of $\mathcal{O}(n)$ of the mentioned algorithms is inevitable, because the input
to these algorithm is a list of values in arbitrary order. Therefore, the algorithm must look at all
the input values to determine a correct solution. If any of these input values will not be
considered it could be the one that should have been returned by the algorithm leading to wrong
results. Apart from this simple and straight forward argument, there is a considerable amount of
research on the exact number of comparisons required for selection, both in the randomized and
deterministic cases.

It has been found that selecting the $i$-th element of $n$ requires at least
$n+\min(i,n-i)-\mathcal{O}(1)$ comparisons, thus matching the average case of the Floyd-Rivest
algorithm up to his $\smallO(n)$ term. For deterministic algorithms it has also been shown that
\begin{eqnarray*}
  &\left (1 + H(i/n) \right ) \cdot n + \Omega(\sqrt n) \\
  &\text{with~} H(x) = x \cdot \log_2 \frac{1}{x} + (1-x) \log_2 \frac{1}{1-x}
\end{eqnarray*}
are required. An upper bound is been proposed by Blum, in the paper \textit{Time Bounds for
  Selection}. It stated that no more than $5.430\dot{5} \cdot n$ comparisons are ever required.
Therefore selection is for sure in a time complexity of $\mathcal{O}(n)$ for best and worst-case.

\begin{lemma}
  If $k$ is a lower bound for selecting $i$ of $n$, then selecting $i$ of $n+1$ must take at least $k+1$ comparisons.
\end{lemma}

\begin{proof}
  Assume some algorithm exists that selects $i$ of $n+1$ in $k$ comparisons. It must have two elements it compares first.
  If we input a by definition largest element in place of one of them the algorithm must still return the correct $i$-th
  largest of the remaining $n$ elements. But because this element is larger by definition, the first comparison may be
  skipped, thus reducing the number of comparisons by at least 1. Thus taking out all occurrences of that element will
  yield an algorithm for $i$ of $n$ in $k-1$ comparisons, which contradicts the precondition of $k$ being a lower bound.
\end{proof}


\subsection{Partial Order}
\label{sec:partial_order}
To dive deeper into these algorithms the concept of partial orders needs to be introduced. A partial
order, often simply called a reflexive, weak, or non-strict partial order, is a homogeneous relation
$\leq$ on a set $P$ that satisfies reflexivity, anti symmetry, and transitivity. For any $a, b, c
  \in P$, it must adhere to the following conditions:

\begin{itemize}
  \item Reflexivity: $a \leq a$, meaning every element is related to itself.
  \item Antisymmetry: If $a \leq b$ and $b \leq a$, then $a = b$, implying no two distinct elements
        precede each other.
  \item Transitivity: If $a \leq b$ and $b \leq c$, then $a \leq c$.
\end{itemize}
A non-strict
partial order is also known as an antisymmetric pre order.

%[\todo{cite:https://en.wikipedia.org/wiki/Partially_ordered_set}]

\subsection{Linear extensions}
A partial order denoted as $\leq^*$ on a set X is considered an extension of
another partial order $\leq$ (see \ref{sec:partial_order}) on the same set $X$
if, for all $x$ and $y$ in $X$, whenever $x \leq y$, it's also true that $x
  \leq^* y$. A linear extension is an extension that maintains a total order. The
most common example in the literature for instance, the lexicographic order of
completely ordered sets serves as a linear extension of their product order.
According to the order-extension principle \cite{Jech1973}, every partial order
can be expanded into a total order.

In computer science, algorithms designed to discover linear extensions of
partial orders, which are often depicted as reachability orders in directed
acyclic graphs, and are used referred to as topological sorting.


\subsection{Example}
\begin{figure}[h!]
  \centering
  \includegraphics[width=0.5\columnwidth]{figures/Median_of_5.svg.png}
  \caption{Finding the median $i=2$ of $n=5$ values using six comparisons.}
  \label{fig:median_of_5}
\end{figure}
A good visual example is finding the median $i=3$ in a list of $n=5$ elements. Figure
(\ref{fig:median_of_5}) illustrate the search of the median using Hasse diagrams. Each step shows
the comparisons to be performed next as a yellow line. A Hasse diagram of the order of relation
found so far (smaller=lower, larger=higher) is shown as the blue lines. The red circles have already
found to be greater than three others and disqualified The red elements have already been determined
to be larger than three other elements and are therefore disqualified as medians. The larger
element of the final comparison is the median. This is also the optimal algorithm for $i=2$ and
$n=5$.


\subsubsection{Solvability}
The solvability of a partial order can be determined in the following way. For each element, count
the elements that are smaller than it and count the elements that are larger than it. If there is an
element that is larger than $n-i$ elements and smaller than $i-1$ elements, this element is the
$i$-th largest element. Thus, the poset is solvable.


\subsubsection{Reduced and Canonified Posets}

If a Poset contains only those elements not yet excludable from being a solution, we call it \textit{reduced}.
Figure (\ref{fig:median_of_5}) for example incorporates this idea by
coloring eliminated elements in red.
Using reduction a Poset is solved if and only if it has only one element, the trivial solution.
We call a reduced Poset \textit{canonified} if it satisfies additional constraints that
aim to reduce the likelyhood of unequal but isomorphic representations.
The different search algorithms used employ different strategies here deepening on whether we
found a more unique representation or cheaper canonification to be more advantagous for
the given application. Explicit approaches will hence be covered individually.


\section{Methods and Tools}
\subsection{Forward Search}\label{chapter:forward_search}
Forward Search starts with an empty Poset, i.e. one with entirely unknown ordering of its elements,
and recursively determines solvability of a given Poset within some bound by exhaustively searching
the results of all possible comparisons to be made unless it is already solved or we determine that
it cannot be solved within the alloted number of comparisons by some heuristic.

Between the two possible outcomes of a comparison we assume the worse, but since an algorithm is
free to choose which elements to compare we are looking for the most useful comparison, the one that
yields result Posets cheapest to solve themselves, still in terms of worst case outcome. The
algorithms output by the search program are built by saving the comparison that lead to this
cheapest to solve result.

To limit memory cost and allow further pruning we traverse the search tree depth first, reducing the
maximum number of comparisons alloted to child Posets to one less than the current best result
found. This premise is implemented by Minimax algorithms as shown in
figure~\ref{fig:minimax_search}.

We can drastically speed up this exploration by caching previous results, even with a simple usage
based ejection policy. Since the search always imposes an upper bound for the number of comparisons
to allow this also includes yet unsolved Posets, for which we note the currently known minimum.

It is optimal because of an inductive argument over the number of relative orders determined. An
already solved Poset obviously takes no further comparisons to solve. Then, given an unsolved Poset
with all elements already too large or small excluded we must make at least one more comparison to
make progress. Since all Posets resulting from these comparisons must have more elements ordered
than the current one has we can assume as per induction that we know their optimal cost. As a result, we
cannot solve the Poset in less than the cost of the cheapest of these comparisons, plus one for the
comparison itself, hence the current Poset is also solved optimally.

It is also complete for a given upper bound, explainable through a similar inductive argument. If
the Poset is solvable within that bound, then at least one of its possible comparisons must have both
outcomes be solvable within the bound lowered by one. Since the search only lowers the bound imposed
on its recursive descendants beyond that once at least one has been solved, we are also guaranteed
to find a solution for the original Poset if it exists within the bound.


\begin{figure}
  \input{figures/tikz_minimax_search_algorithm.tex}
  \caption{Minimax search algorithm}
  \label{fig:minimax_search}
\end{figure}

\subsubsection{Canonification}

When caching the posets we have to check, whether two posets are isomorphic to eachother.
We consider a poset isomorphic to another poset if we can relabel the elements of one poset to obtain the other poset.
This problem is expensive to solve for every poset comparison.

After adding a comparison to a poset, we transform the poset to a canonical form.
All posets, that are isomorphic to eachother should be transformed to the same canonical form.
Computing the canonical form can be done using Nauty, but this takes a significant amount of time.
Some performance tests show that it is faster to compute an almost canonical form, where some posets that are isomorphic to eachother result in different canofied forms.
As a result, some posets that are isomorphic occupy several cache entries, but canonifying a poset is much faster.

\subsection{Backward Search} \label{sec:backward}

Backward search starts with a solved Poset, then repeatedly attempts to remove comparisons from its
frontier Posets such that the same Poset with the opposite comparison result is also found within
those already discovered.

Thus the number of iterations taken until a Poset is added to the frontier equals the number of
worst case comparisons needed to solve it, which means that the search terminates once the empty
Poset with the desired $n$ and $i$ is found.

The argument for the correctness is the number of comparisons we have found all Posets solvable
within them for, equal to the number of iterations of the search. If for a given Poset and a
comparison within it we have already discovered both results then their cost must be less than the
current number of iterations, so the Poset is solvable within that number and because this did not
hold true in a previous iteration the cost must also be optimal. And if a Poset is solvable within
that number of comparisons it must have at least one comparison with a result among the Posets
discovered in the previous iteration, as otherwise it would have to be solvable in less.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% TODO: In Papern suche, ob die Rückwärtssuche wirklich komplett neues Gebiet ist

% TODO: @Johanna: ab hier übersetzen :)

\subsubsection{Normalform} \label{sec:backward:normal_form}

Im Unterschied zur Vorwärtssuche nutzt die Rückwärtssuche eine eindeutige Kanonisierung.
Die Kanonisierung der Vorwärtssuche ist aus Performancegründen nicht eindeutig.

\begin{definition}[Inverses Poset] \label{definition:inverse_poset}
  Das inverse Poset eines Posets $p$ mit $n$ Elementen ist das Poset $q$ mit ebenfalls $n$ Elementen, bei dem alle Vergleiche aus $p$ umgekehrt sind und nicht das $i$-kleinste, sondern das $(n - 1 - i)$-kleinste Element gesucht wird.
\end{definition}

\begin{lemma} \label{lemma:inverse_poset}
  Ein Poset $p$ ist in $k$ Vergleichen lösbar, genau dann, wenn das inverse Poset zu $p$ in $k$ Vergleichen lösbar ist.
\end{lemma}

\begin{proof} \label{proof:inverse_poset}
  % TODO: @Johanna: vielleicht hast du da eine Idee, wie man das aufschreiben könnte
\end{proof}

Um eine eindeutige Darstellung zu gewährleisten, wird zunächst ermittelt, ob $i$ oder $n - 1 - i$ kleiner ist, und gegebenenfalls wird das Poset $p$ durch sein Inverses ersetzt.
Nach Lemma~\ref{lemma:inverse_poset} ändert sich dadurch nichts an seiner Lösbarkeit.

Abschließend werden die Elemente kanonisch angeordnet.
Dazu wird das Poset intern als gerichteter Graph repräsentiert, wobei sich diese Darstellung an den Hasse-Diagrammen orientiert.
Um alle Elemente kanonisch anzuordnen, müssen die Knoten des Graphen kanonisch beschriftet werden.
Hierfür wird primär auf ``nauty'' zurückgegriffen.
Nauty ist ein C-Programm zur Berechnung von Automorphismengruppen von Graphen und kann ein kanonisches Label für einen gegebenen Graphen erzeugen.
% TODO: @Johanna: bibtex cite von https://pallini.di.uniroma1.it/
Durch diese kanonische Beschriftung kann das Poset eindeutig dargestellt werden.

Ein potentielles Problem tritt auf, wenn die Gleichung $i = n - 1 - i$ erfüllt ist.
In diesem Fall ist es nicht möglich, basierend auf dem Wert von $i$ zu unterscheiden, ob $p$ oder sein Inverses der kanonischen Normalform entspricht.

\begin{figure}
  \input{figures/tikz_backward_canonify_problematic.tex}
  \centering
  \caption{Problematischer Fall}
  \label{fig:backward_canonify_problematic}
\end{figure}

Wie aus dem Hasse-Diagramm in Abbildung~\ref{fig:backward_canonify_problematic} ersichtlich ist, erscheinen beide Posets unterschiedlich, obwohl eines das genaue Inverse des anderen ist.
Um diese Unklarheit zu beheben, wird für jedes Poset, für das $i = n - 1 - i$ gilt, zusätzlich das Inverse berechnet und kanonisiert.
Anschließend wird eines der beiden deterministisch ausgewählt.

Da das Kanonisieren für die Rückwärtssuche unvermeidbar ist und einen Großteil der Rechenzeit beansprucht, werden alle trivialen Fälle abgefangen, und nur die verbleibenden Fälle werden mittels nauty kanonisiert.

Zunächst wird für jeden Knoten, ähnlich wie bei der Vorwärtssuche, der Grad der eingehenden und ausgehenden Kanten berechnet.
Anschließend wird ein Hash-Wert für jeden Knoten berechnet.
Dieser berücksichtigt die topologische Struktur aller Nachbarknoten sowie rekursiv bis zu einer gegebenen Grenze deren Nachbarknoten.

Daraufhin werden die Knoten nach ihren Knotengraden sowie den Hash-Werten sortiert.
Wenn jeder Knotengrad bzw. jeder Hash-Wert einzigartig ist, befindet sich der Graph in einer eindeutigen Normalform.
Falls es zwei Knoten mit denselben Vergleichsattributen gibt, wird versucht, diese zu vertauschen.
Sollte sich dabei die interne Darstellung des Posets nicht ändern, kann das Poset als eindeutig kanonisiert betrachtet werden, da beide Graphen auf dieselbe interne Darstellung abbilden.

Sollte das Poset noch nicht eindeutig kanonisiert sein, wird der Fall berücksichtigt, dass es $l$ Paare von Knoten gibt, die auf die gleichen Attribute abbilden.
Anschließend wird über alle möglichen Permutationen iteriert.
Für das erste Paar gibt es beispielsweise zwei Möglichkeiten: Entweder es bleibt so oder die beiden Knoten werden vertauscht.
Da in der Regel nur wenige Knotenpaare mit denselben Attributen vorhanden sind, ist $l$ klein, und die $2^l$ möglichen Permutationen können effizient iteriert werden. Schließlich wird eine der Permutationen deterministisch anhand ihrer internen Darstellung ausgewählt.

Durch die Behandlung dieser trivialen Fälle kann die Notwendigkeit der Verwendung von nauty stark reduziert werden, wie beispielhaft in Tabelle~\ref{table:nauty-ratio} für $n = 13$ dargestellt.

Es ist besonders bemerkenswert, dass mit höherem $i$ der prozentuale Anteil der Aufrufe von nauty abnimmt.
Für kleine Werte von $i$ stellt der hohe prozentuale Anteil von nauty kein Problem dar, da das Ergebnis für kleine $i$ ohnehin schnell berechnet werden kann.

\begin{table}
  \begin{tabular}{l|l}
    $i$ & nauty-Ratio \\
    \hline
    $0$ & $0.000\%$   \\
    $1$ & $30.205\%$  \\
    $2$ & $6.797\%$   \\
    $3$ & $1.530\%$   \\
    $4$ & $0.469\%$   \\
    $5$ & $0.188\%$   \\
    $6$ & $0.116\%$
  \end{tabular}
  \centering
  \caption{Prozentuale Häufigkeit der Aufrufe von nauty zur Kanonisierung}
  \label{table:nauty-ratio}
\end{table}

\subsubsection{Algorithmus} \label{sec:backward:algorithm}

Die Eingabe für die Rückwärtssuche sind die Parameter $n$ und $i$.
Die Rückwärtssuche beginnt mit dem kleinsten gelösten Poset und berechnet iterativ alle Posets, die in $1, 2, 3, \dots$ Vergleichen gelöst werden können, bis das leere Poset mit $n$ Elementen und dem $i$-kleinsten gesuchten Element gefunden wird.
Das kleinste gelöste Poset besteht aus einem Element und enthält keine Vergleiche.
Das leere Poset besteht aus $n$ Elementen, wobei das $i$-kleinste Element gesucht wird, und beinhaltet keinen Vergleich.
Allgemein sei $A_k$ die Menge aller Posets, die in $k$ Vergleichen lösbar sind.
$A_0$ besteht nur aus dem kleinsten gelösten Poset.
Im Folgenden berechnet die Rückwärtssuche für jedes Poset in der Menge $A_k$ die entsprechenden Vorgänger.
Die Menge aller Vorgänger bildet die Menge $A_{k + 1}$.
Wenn das leere Poset mit $n$ Elementen und dem $i$-kleinsten gesuchten Element in $A_l$ vorhanden ist, werden genau $l$ Vergleiche benötigt, um das $i$-kleinste Element einer $n$-elementigen Liste zu bestimmen.

\subsubsection{Vorgängerberechnung} \label{sec:backward:predecessor_calculation}

\begin{definition}[Vorgänger] \label{definition:predecessor_calculation}
  Poset $q$ ist Vorgänger von Poset $p$, wenn folgende Eigenschaften gelten:
  \begin{itemize}
    \item $q$ ist reduziert und eindeutig kanonisiert.
    \item $q$ wurde in keiner vorherigen Runde gefunden (da es sonst in weniger Vergleichen lösbar wäre).
    \item Es existiert ein Vergleich $(i, j)$, durch dessen Hinzunahme in $q$ und anschließende Normalisierung wieder das Poset $p$ resultiert und durch Hinzunahme des umgekehrten Vergleichs $(j, i)$ und anschließende Normalisierung ein bereits gefundenes Poset resultiert.
  \end{itemize}
\end{definition}

\begin{lemma} \label{lemma:predecessor_calculation}
  Wenn Poset $p$ in $k$ Vergleichen lösbar ist und $q$ ein Vorgänger von Poset $p$ ist, ist Poset $q$ in $k + 1$ Vergleichen lösbar
\end{lemma}

\begin{proof} \label{proof:predecessor_calculation}
  Da $q$ in keiner vorherigen Runde gefunden wurde, ist es gemäß Annahme nicht in weniger Vergleichen lösbar.
  Da ein Vergleich $(i, j)$ existiert, durch dessen Hinzunahme und anschließende Normalisierung das Poset $p$ resultiert, kann $q$ durch die Hinzunahme eines Vergleichs erreicht werden.
  Da $p$ in $k$ Vergleichen lösbar ist, ist somit $q$ in $k + 1$ Vergleichen lösbar.
  Wenn der Vergleich umgekehrt eingefügt wird, befindet sich das resultierende Poset, gemäß Annahme, bereits im Cache.
  Dadurch ist dieser Pfad in höchstens $k + 1$ Vergleichen lösbar.
\end{proof}

Da potenziell unendlich viele Vorgänger existieren, werden diese nur bis zu einer maximalen Grenze von $n_{\text{max}}$ Elementen berechnet.
Die Berechnung eines Vorgängers für ein gegebenes Poset $p$ mit $n$ Elementen, bei dem das $i$-kleinste Element gesucht wird, erfolgt in drei Schritten:

\begin{itemize}
  \item[1.]
    Zunächst werden alle Posets mit $n$ Elementen gesucht, die durch das Einfügen eines Vergleichs, gefolgt von der Kanonisierung, wieder in Poset $p$ resultieren.

    Eine Schwierigkeit stellen die transitiven Vergleiche dar, da durch das Einfügen eines Vergleichs mehrere Vergleiche miteingefügt werden können.

    \begin{figure}
      \centering
      \input{figures/tikz_problematic_case.tex}
      \caption{Problematischer Fall mit transitiven Vergleichen}
      \label{fig:backward_problematic}
    \end{figure}

    Wie in Abbildung~\ref{fig:backward_problematic} veranschaulicht, sind alle drei Posets vollständig reduziert und kanonisiert.
    Durch das Einfügen eines Vergleichs in Poset (2) oder in Poset (3) kann beide Male Poset (1) resultieren.
    Das bedeutet, dass je nach aktuellem Cache Poset (2) und Poset (3) potentielle Vorgänger sind, obwohl beide Male der gleiche Vergleich eingefügt wird.

    Um dieses Problem zu lösen, werden alle potentiellen Vorgänger berechnet.

  \item[2.]
    Im nächsten Schritt werden alle Vorgänger berechnet, die $n + 1$ Elemente haben und durch Einfügen eines Vergleichs gefolgt von einer Kanonisierung erneut das Poset $p$ ergeben.

    Da das neue Element kleiner oder größer als das gesuchte $i$-kleinste Element ist, wird bei diesen Vorgängern nach dem $i + 1$-kleinsten bzw. dem $i$-kleinsten Element gesucht.
    Da das Poset $p$ kanonifiziert ist, gilt $i \leq n - 1 - i$ für $p$.
    Durch das Kanonifizieren des Posets mit $n + 1$-Elementen und dem $(i + 1)$-kleinsten gesuchten Element, kann es hier jedoch nötig sein das Inverse Poset zu bilden wodurch das $(n + 1) - (i + 1) - 1 = n - i + 1$-te Element gesucht ist.

    Hierfür wird in Poset $p$ ein neues Element sowie passende Vergleiche eingefügt.
    Passende Vergleiche bedeutet, dass das neue Element nicht unmittelbar wegreduziert werden darf und es noch einen Vergleich gibt, der eingefügt werden könnte, ohne dass das neue Element wegreduziert werden kann, nach Lemma~\ref{lemma:remove_only_last_element_edge}.

    \begin{lemma} \label{lemma:remove_only_last_element_edge}
      Um alle möglichen Vorgänger mit $n + 1$ Elementen zu konstruieren, müssen nur Vergleiche zwischen dem neuen Element und beliebig vielen anderen Elemente hinzugefügt werden.
    \end{lemma}

    \begin{proof} \label{proof:remove_only_last_element_edge}
      Angenommen, es existiert ein Vorgänger mit $n + 1$ Elementen, bei dem das $(n + 1)$-te Element wegreduziert werden kann, wenn ein Vergleich zwischen dem $i$-ten und dem $j$-ten Element eingefügt wird, wobei $0 \leq i < j \leq n$.
      Dann ... % TODO: idk
    \end{proof}

    Anschließend werden die Posets aus dem 1. und 2. Schritt in einer Menge zusammengeführt und es wird sichergestellt, dass alle Posets kanonisiert sind.
    Bezeichne den Vergleich, der eingefügt werden könnte, ohne das ein Element wegreduziert werden kann im folgenden als den entfernten Vergleich.

  \item[3.]
    Im dritten Schritt wird für jedes bereits gefundene Element iterativ neue Elemente eingefügt, bis die obere Grenze $n_{\text{max}}$ erreicht ist.
    Wenn ein neues Element eingefügt wird, muss beachtet werden, dass eventuell nicht mehr das $i$-kleinste, sondern das $(i + 1)$-kleinste Element gesucht wird, genau wie im 2. Schritt, und das neue Element nicht direkt wegreduziert werden kann.
    Des Weiteren muss durch das Einfügen im 1. und 2. Schritt entferten Vergleichs und anschließendem reduzieren sowie kanonifizieren wieder Poset $p$ resultieren.

  \item[4.]
    Im letzten Schritt wird für jeden Vorgänger die minimale Anzahl an Vergleichen berechnet, die noch entfernt werden müssen, bis das leere Poset erreicht ist.
    Diese Anzahl entspricht den Kanten im zugehörigen Hasse-Diagramm.
    Anhand der bekannten theoretischen oberen Schranken können alle Posets verworfen werden, die zu viele Vergleiche enthalten, da diese zu keinem leeren Poset in den verbleibenden Vergleichen führen können und somit auch in der Vorwärtssuche nicht betrachtet werden können.
\end{itemize}

Da die theoretischen oberen Schranken in der Praxis zu hoch sind, verwendet das Programm einen iterative deepening-Ansatz.
Dieser beginnt mit einer oberen Grenze, die der theoretischen unteren Schranke entspricht, und erhöht diese Grenze iterativ, bis schließlich eine Lösung gefunden wird.
Obwohl dieser Ansatz dazu führt, dass die Rückwärtssuche mehrfach neu gestartet wird, da keine Ergebnisse aus vorherigen Runden übernommen werden können, kann dadurch der Suchraum erheblich eingeschränkt werden.

% TODO: Hier muss ein Bild vom Suchbaum hin für z.B. 4,1 (also schöner)
\begin{figure}[h!]
  \centering
  \includegraphics[width=\columnwidth]{figures/backward-search-tree.jpg}
  \caption{Suchbaum für $n = 4, i = 1$}
  \label{fig:backward-search-tree}
\end{figure}

\input{figures/tikz_posets_per_level.tex}

\subsubsection{Parallelisierung} \label{sec:backward:parallelisation}
Die Rückwärtssuche kann effizient parallelisiert werden, indem die Berechnung der Vorgänger parallel durchgeführt wird.

\begin{table}
  \begin{tabular}{l|l|l}
    % TODO: Zahlen erheben -> brauche Server
    Anzahl der Kerne & Zeit      & Effizienz \\
    \hline
    $1$              & $23.341s$ & $1.000$   \\
    $2$              & $12.710s$ & $0.918$   \\
    $3$              & $8.654s$  & $0.899$   \\
    $4$              & $6.765s$  & $0.863$   \\
  \end{tabular}
  \centering
  \caption{Effizienz der Parallelität für $n = 11, i = 5$}
  \label{table:backward-parallel}
\end{table}

Wie in Tabelle~\ref{table:backward-parallel} für $n = 11, i = 5$ dargestellt, skaliert die Rückwärtssuche relativ gut mit der Anzahl der Kerne.
Die Effizienz ist hierbei zwischen 0 und 1.
Umso höher der Wert, desto besser die Paralleisierung.
Die Effizienz kann wie folgt berechnet werden:
\[
  \text{Effizienz} = \cfrac{\text{single-core time}}{\text{number of cores} \cdot \text{multi-core time}}
\]

\subsection{Bidirektionale Suche} \label{sec:bidirectional}

Bei der bidirektionalen Suche werden sowohl die Vorwärts- als auch Rückwärtssuche gleichzeitig gestartet.
Es ist zu beachten, dass die Rückwärtssuche mit der theoretischen oberen Schranke gestartet wird und nicht den iterativen deepening-Ansatz verwendet, wie es bei der reinen Rückwärtssuche der Fall ist.
Während der Rückwärtssuche werden alle bereits gefundenen Posets in einem globalen Cache gespeichert und zusätzlich bis zu welcher Ebene der Cache vollständig ist, das heißt, in welcher Ebene sie sich derzeit befindet.
Diese Ebene sei im Folgenden als $k$ bezeichnet.
Die Vorwärtssuche wird abgebrochen, wenn höchstens $k$ Vergleiche übrig sind und gibt die genaue Grenze zurück, falls sich das Poset im Cache der Rückwärtssuche befindet.
Andernfalls wird zurückgegeben, dass mindestens $k + 1$ Vergleiche erforderlich sind.

\begin{figure}[h!]
  \input{figures/tikz_backward_forward.tex}
  \centering
  \caption{Anzahl Posets vs. Anzahl Vergleiche für $n=13, i=6$ (rot: Rückwärtssuche, blau: Vorwärtssuche)}
  \label{fig:backward_forward_count}
\end{figure}

Wie in Abbildung~\ref{fig:backward_forward_count} zu sehen, durchsucht die Vorwärtssuche für $n = 13, i = 6$ die meisten Posets bei $k = 6$ Vergleichen, während die Rückwärtssuche die meisten Posets bei $k = 14$ durchsucht.
Dies ist sehr unvorteilhaft für eine bidirektionale Suche, da der Großteil des Suchraums vor dem Treffpunkt beider Suchen liegt.

% TODO: Ergebnisse der Bidirektionalen Suche vorstellen

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Pruning Decisions}
The minimax search algorithm explained in chapter~\ref{chapter:forward_search} allows for cutting off unpromising branches. For this means, the following strategies are applied.

\begin{enumerate}
  \item[1.]
    Use solvable-heuristic. A heuristic is employed to estimate whether a poset is solvable. If the heuristic's estimate states 'unsolvable', the branch is pruned.
    Otherwise, the search continues regularly.
  \item[2.]
    Use \texttt{current\_best}. Each call of \texttt{search\_rec} gets a maximum numbers of comparisons.
    When searching the children of a node, the limit is the best (minimal) value found so far.
\end{enumerate}

\subsection{Compatible Posets}

\section{Results}

\begin{table}
  \centering
  \begin{tabular}{c|cccccccc}
    $n$ & \multicolumn{8}{c}{$i$}                                   \\
        & 0                       & 1  & 2  & 3  & 4  & 5  & 6  & 7 \\ \hline
    1   & 0                                                         \\
    2   & 1                                                         \\
    3   & 2                       & 3                               \\
    4   & 3                       & 4                               \\
    5   & 4                       & 6  & 6                          \\
    6   & 5                       & 7  & 8                          \\
    7   & 6                       & 8  & 10 & 10                    \\
    8   & 7                       & 9  & 11 & 12                    \\
    9   & 8                       & 11 & 12 & 14 & 14               \\
    10  & 9                       & 12 & 14 & 15 & 16               \\
    11  & 10                      & 13 & 15 & 17 & 18 & 18          \\
    12  & 11                      & 14 & 17 & 18 & 19 & 20          \\
    13  & 12                      & 15 & 18 & 20 & 21 & 22 & 23     \\
    14  & 13                      & 16 & 19 & 21 & 23 & 24 & 25     \\
    15  & 14                      & 17 & 20 & 23 & 24 & 26 & 26 & ? \\
  \end{tabular}
  \caption{The minimum amount of comparisons needed to select the $i+1$-th smallest of $n$}
  \label{table:num-comparisons}
\end{table}

See Table~\ref{table:num-comparisons}.


\subsection{Search evaluation}
\subsubsection{Backward search}
\subsubsection{bidirectional search}
\subsubsection{forward search}

\subsection{Algorithmic improvements}

\subsubsection{Heuristics}

We used multiple heuristics to estimate if a poset is solvable in a given number of comparisons.
These heuristics are used to reject posets, that are not solvable in the given number of comparisons.
This reduces the number of posets that need to be searched.

The first heuristic uses the number of compatible posets.
We use the fact, that the number of comparisons needed to solve a poset is less than the base two logarithm of the number of compatible posets,
to estimate if a poset is solvable.

The second heuristic searches for two elements which have not beend compared yet.
One of these two elements is maximal and has at least two elements smaller than it,
and the other element is minimal and has at least two elements greater than it.
We then construct a new poset with a comparison added, where the minimal element is smaller than the maximal.
The new poset is then searched for a solution using the forward seach described above.
If the new poset is found to be solvable in the given number of comparisons, we estimate that the original poset is also solvable.
If the new poset is not solvable, we estimate the original is not solvable either.
This heuristic can be slightly improved by maximising the number of elements smaller than the maximal element and greater than the minimal element.

\subsubsection{Triangular Adjacency Matrix}
Storing an adjacency matrix for a poset of size $n$ takes $n^2 - n$ bits, one for each possible relation.
The diagonal does not need to be stored, as an element can not be smaller than itself.

By canonifying the poset, the elements can be sorted in a way such that each element is not smaller than any element before it.
This property can be used to reduce the adjacency matrix to a triangular matrix, which can then be stored using $\frac{n^2 - n}{2}$ bits.
It can also simplify some algorithms, for example calculating the number of compatible posets.

\subsubsection{Multithreading}

\section{Conclusion}
We found a better solution hooray!
These are points we'd like to take into account for further research


\appendices
\section{Proof of the First Zonklar Equation}
Appendix one text goes here.
\section{}
Appendix two text goes here.


\ifCLASSOPTIONcompsoc
  \section*{Acknowledgments}
\else
  \section*{Acknowledgment}
\fi


The authors would like to thank...

\ifCLASSOPTIONcaptionsoff
  \newpage
\fi


\bibliographystyle{IEEEtran}
\bibliography{biblio.bib}
\end{document}